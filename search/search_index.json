{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>kdef aims to provide an easy way to manage resources in a Kafka cluster by having them defined explicitly in a human-readable format. Changes to resource definitions can be reviewed like code and applied to a cluster.</p> <p>kdef was designed to support being run in a CI-CD environment, allowing teams to manage Kafka resource definitions in source control with pull requests (GitOps).</p> <p></p>"},{"location":"#features","title":"Features","text":"<ul> <li>Definition support for:<ul> <li>Topics</li> <li>ACLs</li> <li>Per-broker configs</li> <li>Cluster-wide broker configs</li> </ul> </li> <li>YAML and JSON definition formats</li> <li>TLS and SASL mechanisms (PLAIN, SCRAM, AWS_MSK_IAM)</li> <li>CLI scripting support (input via stdin, JSON output, etc.)</li> </ul>"},{"location":"#compatibility","title":"Compatibility","text":"<p>kdef uses Kafka broker APIs. These are the minimum Kafka versions required to apply each definition kind.</p> <ul> <li><code>acl</code> (Kafka 0.11.0+)</li> <li><code>broker</code> (Kafka 0.11.0+)</li> <li><code>brokers</code> (Kafka 0.11.0+)</li> <li><code>topic</code> (Kafka 2.4.0+)</li> </ul>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#sources","title":"Sources","text":"<p>kdef sources configuration in the following ways.</p>"},{"location":"configuration/#config-file","title":"Config file","text":"<p>kdef attempts to source configuration from a file named <code>config.yml</code> in the current working directory. Override this default behaviour by specifying the path to a file with the <code>--config-path</code> global option.</p> <p>The easiest way to create a configuration file for your cluster is to run through the short interactive prompt.</p> <pre><code>kdef configure\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment variables","text":"<p>kdef attempts to source configuration from <code>KDEF__</code> prefixed environment variables. Environment variables override config file configuration.</p> <pre><code>KDEF__SEED_BROKERS=\"b-1.example.amazonaws.com:9098,b-2.example.amazonaws.com:9098\" \\\nKDEF__ALTER_CONFIGS_METHOD=\"incremental\" \\\nKDEF__TLS__ENABLED=\"true\" \\\nKDEF__SASL__METHOD=\"aws_msk_iam\" \\\nkdef export topic\n</code></pre>"},{"location":"configuration/#command-line-options","title":"Command-line options","text":"<p>kdef attempts to source configuration from the <code>-X</code> command-line option. Command-line supplied configuration overrides both config file configuration and environment variables.</p> <pre><code>kdef export topic \\\n  -X seedBrokers=b-1.example.amazonaws.com:9098,b-2.example.amazonaws.com:9098 \\\n  -X alterConfigsMethod=incremental \\\n  -X tls.enabled=true \\\n  -X sasl.method=aws_msk_iam\n</code></pre>"},{"location":"configuration/#config","title":"Config","text":"<ul> <li> <p>seedBrokers ([]string)</p> <p>One or more seed broker addresses. The default value is <code>localhost:9092</code>.</p> </li> <li> <p>tls (TLSConfig)</p> </li> <li> <p>sasl (SASLConfig)</p> </li> <li> <p>timeoutMs (int)</p> <p>Timeout in milliseconds for API requests that support timeouts. The default value is <code>5000</code>.</p> </li> <li> <p>alterConfigsMethod (string)</p> <p>The method to use when altering configs. Must be one of <code>auto</code>, <code>incremental</code>, <code>non-incremental</code>. The default value is <code>auto</code>.</p> <p>Kafka 2.3.0+ supports \"incremental alter configs,\" an improved API for altering configs. When set to <code>auto</code>, kdef detects what the cluster supports and use <code>incremental</code> if available. Setting <code>incremental</code> or <code>non-incremental</code> saves an API call to determine what the cluster supports.</p> <p>Note that if the cluster contains brokers with a mix of Kafka versions, some Kafka 2.3.0+ and some Kafka &lt;2.3.0, then <code>non-incremental</code> should be used.</p> </li> </ul>"},{"location":"configuration/#tlsconfig","title":"TLSConfig","text":"<ul> <li> <p>enabled (bool)</p> <p>Set to <code>true</code> if connecting to cluster brokers requires TLS. The default value is <code>false</code>.</p> </li> <li> <p>caCertPath (string)</p> <p>Path to a CA cert.</p> </li> <li> <p>clientCertPath (string)</p> <p>Path to a client cert.</p> </li> <li> <p>clientKeyPath (string)</p> <p>Path to a client key.</p> </li> <li> <p>serverName (string)</p> <p>Set if connecting via TLS requires a distinct server name. When connecting via TLS, by default the client uses the hostname or IP address of the connected broker as the TLS server name.</p> </li> </ul>"},{"location":"configuration/#saslconfig","title":"SASLConfig","text":"<ul> <li> <p>method (string)</p> <p>The required SASL method. Must be one of <code>plain</code>, <code>scram-sha-256</code>, <code>scram-sha-512</code>, <code>aws-msk-iam</code>.</p> </li> <li> <p>user (string)</p> <p>SASL username.</p> </li> <li> <p>pass (string)</p> <p>SASL password.</p> </li> <li> <p>isToken (bool)</p> <p>Set to <code>true</code> if the SASL is from a delegation token.</p> </li> </ul>"},{"location":"configuration/#examples","title":"Examples","text":""},{"location":"configuration/#saslplain","title":"SASL/PLAIN","text":"<p>The following configuration can be used to access clusters on Confluent Cloud.</p> <pre><code>seedBrokers:\n  - \"b-1.example.com:9092\"\n  - \"b-2.example.com:9092\"\n  - \"b-3.example.com:9092\"\ntimeoutMs: 5000\ntls:\n  enabled: true\nsasl:\n  method: plain\n  user: alice\n  pass: alice-secret\n</code></pre>"},{"location":"configuration/#amazon-msk","title":"Amazon MSK","text":"<p>The following configuration can be used to access an Amazon MSK cluster with IAM Access Control enabled.</p> <pre><code>seedBrokers:\n  - \"b-1.example.amazonaws.com:9098\"\n  - \"b-2.example.amazonaws.com:9098\"\n  - \"b-3.example.amazonaws.com:9098\"\ntimeoutMs: 10000\ntls:\n  enabled: true\nsasl:\n  method: aws_msk_iam\n</code></pre> <p>When executing kdef, the AWS SDK must be instructed as to where credentials can be sourced. See here for further documentation.</p> <pre><code>AWS_SDK_LOAD_CONFIG=1 AWS_PROFILE=my-profile kdef export topic\n</code></pre>"},{"location":"getting-started/","title":"Getting started","text":"<p>This short tutorial introduces some of the main features of kdef.</p>"},{"location":"getting-started/#tutorial-setup","title":"Tutorial setup","text":"<ol> <li> <p>Clone the kdef repository and change directory to <code>docs/tutorial</code>.</p> <pre><code>git clone git@github.com:peter-evans/kdef.git\ncd kdef/docs/tutorial\n</code></pre> </li> <li> <p>Execute the following to spin up a two-broker Kafka cluster using Docker compose.</p> <pre><code>ZOOKEEPER_PORT=12181 \\\nBROKER1_PORT=19092 \\\nBROKER2_PORT=19093 \\\ndocker-compose up -d\n</code></pre> <p>At the end of the tutorial use the following to bring the cluster down. <pre><code>ZOOKEEPER_PORT=12181 \\\nBROKER1_PORT=19092 \\\nBROKER2_PORT=19093 \\\ndocker-compose down --volumes\n</code></pre></p> </li> <li> <p>Your current working directory should now be <code>docs/tutorial</code>.     In this directory is a <code>config.yml</code> configuration file.     This is the configuration kdef will use to connect to the Kafka cluster spun up in the previous step.</p> </li> </ol>"},{"location":"getting-started/#applying-definitions","title":"Applying definitions","text":"<p>The cluster we spun up in the previous section has no resources. Let's apply some definitions.</p>"},{"location":"getting-started/#from-files","title":"from files","text":"<ol> <li> <p>Execute the following to perform a dry-run apply of all definitions under the \"definitions\" directory.</p> <pre><code>kdef apply \"definitions/**/*.yml\" --dry-run\n</code></pre> </li> <li> <p>Remove the <code>--dry-run</code> flag and apply the definitions.</p> <pre><code>kdef apply \"definitions/**/*.yml\"\n</code></pre> </li> <li> <p>Execute the command in step 2 a second time. You should now see that there are \"no changes to apply.\"</p> </li> <li> <p>Edit <code>definitions/topic/tutorial_topic1.yml</code> and make the following changes.</p> <ul> <li><code>retention.ms: \"43200000\"</code></li> <li><code>partitions: 6</code></li> </ul> </li> <li> <p>Execute steps 1 and 2 again to dry-run and then apply the topic definition update.</p> </li> </ol>"},{"location":"getting-started/#from-stdin","title":"from stdin","text":"<ol> <li> <p>Execute the following to perform a dry-run apply of a definition passed via stdin.</p> <pre><code>cat &lt;&lt;EOF | kdef apply - --dry-run\napiVersion: v1\nkind: topic\nmetadata:\n  name: tutorial_topic2\nspec:\n  configs:\n    retention.ms: \"86400000\"\n  partitions: 3\n  replicationFactor: 2\nEOF\n</code></pre> </li> <li> <p>Remove the <code>--dry-run</code> flag and apply the definition.</p> <pre><code>cat &lt;&lt;EOF | kdef apply -\napiVersion: v1\nkind: topic\nmetadata:\n  name: tutorial_topic2\nspec:\n  configs:\n    retention.ms: \"86400000\"\n  partitions: 3\n  replicationFactor: 2\nEOF\n</code></pre> </li> <li> <p>Execute the command in step 2 a second time. You should now see that there are \"no changes to apply.\"</p> </li> <li> <p>Execute the following to perform a dry-run apply and update the topic created in step 2.     This time we'll supply the definition as JSON.</p> <pre><code>cat &lt;&lt;EOF | kdef apply - --format json --dry-run\n{\n  \"apiVersion\": \"v1\",\n  \"kind\": \"topic\",\n  \"metadata\": {\n    \"name\": \"tutorial_topic2\"\n  },\n  \"spec\": {\n    \"configs\": {\n      \"retention.ms\": \"43200000\"\n    },\n    \"partitions\": 6,\n    \"replicationFactor\": 2\n  }\n}\nEOF\n</code></pre> </li> <li> <p>Remove the <code>--dry-run</code> flag and apply the definition update.</p> <pre><code>cat &lt;&lt;EOF | kdef apply - --format json\n{\n  \"apiVersion\": \"v1\",\n  \"kind\": \"topic\",\n  \"metadata\": {\n    \"name\": \"tutorial_topic2\"\n  },\n  \"spec\": {\n    \"configs\": {\n      \"retention.ms\": \"43200000\"\n    },\n    \"partitions\": 6,\n    \"replicationFactor\": 2\n  }\n}\nEOF\n</code></pre> </li> </ol>"},{"location":"getting-started/#exporting-definitions","title":"Exporting definitions","text":"<p>Let's export definitions for the resources we created in the previous section.</p>"},{"location":"getting-started/#to-files","title":"to files","text":"<ol> <li> <p>Execute the following to export <code>topic</code> definitions to files in the directory \"exported\".</p> <pre><code>kdef export topic --output-dir exported\n</code></pre> </li> <li> <p>Let's additionally export partition assignments for the topics and overwrite the files created in step 1.</p> <pre><code>kdef export topic --output-dir exported --overwrite --assignments broker\n</code></pre> </li> </ol>"},{"location":"getting-started/#to-stdout","title":"to stdout","text":"<ol> <li> <p>Execute the following to export <code>topic</code> definitions to stdout.     <code>--quiet</code> suppresses log messages so we just see the definitions output.</p> <pre><code>kdef export topic --quiet\n</code></pre> </li> <li> <p>Alternatively, we can export as JSON.</p> <pre><code>kdef export topic --quiet --format json\n</code></pre> </li> </ol>"},{"location":"install/","title":"Installation","text":"<p>Install the pre-compiled binary, use Docker, or compile from source.</p>"},{"location":"install/#install-the-pre-compiled-binary","title":"Install the pre-compiled binary","text":"<p>Install the pre-compiled binary via one of the following methods.</p>"},{"location":"install/#homebrew-tap","title":"homebrew tap","text":"<pre><code>brew install peter-evans/kdef/kdef\n</code></pre>"},{"location":"install/#go-install","title":"go install","text":"<pre><code>go install github.com/peter-evans/kdef@latest\n</code></pre> <p>Install a specific version by using a suffix in the format <code>@x.x.x</code>.</p>"},{"location":"install/#manually","title":"manually","text":"<p>Download the pre-compiled binaries from the releases page and copy them to the desired location.</p> <p>Info</p> <p>If you would like to see the kdef binary released via a method not listed please make an issue to discuss its feasibility.</p>"},{"location":"install/#running-with-docker","title":"Running with Docker","text":"<p>kdef can also be executed within a Docker container.</p> <p>Registries:</p> <ul> <li><code>peterevans/kdef</code></li> <li><code>ghcr.io/peter-evans/kdef</code></li> </ul> <p>Example usage:</p> <pre><code>docker run --rm \\\n    -v $PWD:/var/opt/kdef/my-cluster \\\n    peterevans/kdef \\\n    apply \"/var/opt/kdef/my-cluster/resources/**/*.yml\" \\\n        --config-path=\"/var/opt/kdef/my-cluster/config.yml\" \\\n        --dry-run\n</code></pre> <p>If connecting to a locally running Kafka cluster you may need to use <code>--net=host</code> to run the container in the host network.</p>"},{"location":"install/#compiling-from-source","title":"Compiling from source","text":"<p>If you would like to build from source follow these steps:</p> <p>clone:</p> <pre><code>git clone https://github.com/peter-evans/kdef\ncd kdef\n</code></pre> <p>get dependencies:</p> <pre><code>go mod tidy\n</code></pre> <p>build:</p> <pre><code>go build -o kdef .\n</code></pre> <p>verify:</p> <pre><code>./kdef --version\n</code></pre>"},{"location":"install/#updating","title":"Updating","text":"<p>Important</p> <p>Until kdef reaches <code>v1.0.0</code> and is considered stable, there could be breaking changes in minor releases. Make sure to check the release notes before updating.</p>"},{"location":"ci/github-actions/","title":"GitHub Actions","text":"<p>kdef can be used in GitHub Actions workflows. This allows changes to Kafka resource definitions to be reviewed with pull requests and applied on merge (GitOps).</p>"},{"location":"ci/github-actions/#pull-request-workflow","title":"Pull request workflow","text":"<p>The following example workflow is a good starting point. It assumes definition files are located under a directory called <code>defs</code>.</p> <p>Pull requests will execute the apply with <code>--dry-run</code>, allowing the diff to be reviewed in the Actions run log. On merge to the default branch the definitions are applied.</p> <p>This example demonstrates passing secrets for SASL mechanism authentication. This is preferable to committing sensitive credentials to the repository in <code>config.yml</code>.</p> <pre><code>name: kdef\non:\n  push:\n    branches: main\n  pull_request:\n    branches: main\n\njobs:\n  apply:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Install kdef\n        uses: jaxxstorm/action-install-gh-release@v1\n        with:\n          repo: peter-evans/kdef\n          tag: v0.4.0\n\n      - name: Toggle dry-run\n        id: vars\n        run: |\n          if [[ \"${{ github.event_name }}\" == \"push\" ]] &amp;&amp; [[ \"${{ github.ref }}\" == \"refs/heads/main\" ]]; then\n              echo \"dry-run=\" &gt;&gt; $GITHUB_OUTPUT;\n          else\n              echo \"dry-run=--dry-run\" &gt;&gt; $GITHUB_OUTPUT;\n          fi\n\n      - uses: actions/checkout@v3\n\n      - name: Apply definitions\n        run: |\n          kdef \\\n            -X sasl.user=${{ secrets.SASL_USER }} \\\n            -X sasl.pass=${{ secrets.SASL_PASS }} \\\n            apply defs/**/*.yml \\\n              ${{ steps.vars.outputs.dry-run }} \\\n              --continue-on-error\n</code></pre>"},{"location":"ci/github-actions/#manual-workflow","title":"Manual workflow","text":"<p>It may be desirable to manually run workflows in some situations.</p> <p>In this <code>workflow_dispatch</code> example, a rebalance operation is triggered by setting the property override <code>-P topic.spec.managedAssignments.balance=all</code>.</p> <pre><code>name: rebalance\non:\n  workflow_dispatch:\n    inputs:\n      dryrun:\n        description: 'dry-run (true/false)'\n        required: true\n        default: true\n\njobs:\n  apply:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Install kdef\n        uses: jaxxstorm/action-install-gh-release@v1\n        with:\n          repo: peter-evans/kdef\n          tag: v0.4.0\n\n      - name: Toggle dry-run\n        id: vars\n        run: |\n          if [[ \"${{ github.event.inputs.dryrun }}\" == \"false\" ]]; then\n              echo \"dry-run=\" &gt;&gt; $GITHUB_OUTPUT;\n          else\n              echo \"dry-run=--dry-run\" &gt;&gt; $GITHUB_OUTPUT;\n          fi\n\n      - uses: actions/checkout@v3\n\n      - name: Apply definitions\n        run: |\n          kdef \\\n            -X sasl.user=${{ secrets.SASL_USER }} \\\n            -X sasl.pass=${{ secrets.SASL_PASS }} \\\n            apply defs/**/*.yml \\\n              ${{ steps.vars.outputs.dry-run }} \\\n              --continue-on-error \\\n              -P topic.spec.managedAssignments.balance=all\n</code></pre>"},{"location":"cmd/apply/","title":"apply","text":"<p>Apply definitions to a Kafka cluster.</p>"},{"location":"cmd/apply/#synopsis","title":"Synopsis","text":"<pre><code>kdef apply &lt;definitions&gt;... [options]\nkdef apply - [options]\n</code></pre> <p><code>&lt;definitions&gt;...</code> represents one or more glob patterns matching the paths of definitions to apply. Directories matching patterns are ignored.</p> <p><code>-</code> instructs kdef to read definitions from stdin.</p>"},{"location":"cmd/apply/#compatibility","title":"Compatibility","text":"<p>kdef uses Kafka broker APIs. These are the minimum Kafka versions required to apply each definition kind.</p> <ul> <li><code>acl</code> (Kafka 0.11.0+)</li> <li><code>broker</code> (Kafka 0.11.0+)</li> <li><code>brokers</code> (Kafka 0.11.0+)</li> <li><code>topic</code> (Kafka 2.4.0+)</li> </ul>"},{"location":"cmd/apply/#examples","title":"Examples","text":"<p>Apply all definitions in directory \"topics\" (dry-run). <pre><code>kdef apply \"topics/*.yml\" --dry-run\n</code></pre></p> <p>Apply definitions in all directories under \"resources\" (dry-run). <pre><code>kdef apply \"resources/**/*.yml\" --dry-run\n</code></pre></p> <p>Apply a topic definition from stdin (dry-run). <pre><code>cat topics/my_topic.yml | kdef apply - --dry-run\n</code></pre></p>"},{"location":"cmd/apply/#options","title":"Options","text":"<ul> <li> <p>--format / -f (string)</p> <p>Resource definition format. Must be either <code>yaml</code> or <code>json</code>. The default value is <code>yaml</code>.</p> </li> <li> <p>--dry-run / -d (bool)</p> <p>Validate and review the operation only. The default value is <code>false</code>.</p> </li> <li> <p>--exit-code / -e (bool)</p> <p>Implies <code>--dry-run</code> and causes the program to exit with 1 if there are unapplied changes and 0 otherwise. The default value is <code>false</code>.</p> </li> <li> <p>--json-output / -j (bool)</p> <p>Implies <code>--quiet</code> and outputs JSON apply results. The default value is <code>false</code>.</p> <p>Schema: <pre><code>[\n    {\n        \"local\": object, // local definition\n        \"remote\": object, // remote definition\n        \"data\": null|object, // additional data\n        \"diff\": string,\n        \"error\": string,\n        \"applied\": bool\n    }\n]\n</code></pre> For definition and additional data schemas see the documentation for each definition.</p> </li> <li> <p>--continue-on-error / -c (bool)</p> <p>Applying resource definitions is not interrupted if there are errors. The default value is <code>false</code>.</p> </li> <li> <p>--reass-await-timeout / -r (int)</p> <p>Time in seconds to wait for topic partition reassignments to complete before timing out. The default value is <code>0</code>.</p> <p>Changes to partition assignments will be reflected immediately by Kafka. However, partition reassignment operations will be queued internally and may take time to complete. While reassignment operations are in progress for a topic, Kafka rejects further partition changes.</p> <p>By default kdef does not wait for reassignment operations to complete and exits immediately. Optionally, kdef can be instructed with this option to await the completion of partition reassignments.</p> </li> <li> <p>--prop-override / -P ([]string)</p> <p>Definition property override for overridable properties (e.g. <code>-P topic.spec.managedAssignments.balance=all</code>). This is a repeatable option.</p> <p>Overridable properties:</p> <ul> <li><code>topic.spec.managedAssignments.balance</code></li> <li><code>topic.spec.maintainLeaders</code></li> </ul> </li> </ul>"},{"location":"cmd/apply/#global-options","title":"Global options","text":"<ul> <li> <p>-no-color (bool)</p> <p>Disable colored output. The default value is <code>false</code>.</p> </li> <li> <p>--quiet / -q (boolean)</p> <p>Enable quiet mode (output errors only). The default value is <code>false</code>.</p> </li> <li> <p>--verbose / -v (boolean)</p> <p>Enable debug output. The default value is <code>false</code>.</p> </li> <li> <p>--config-path / -p (string)</p> <p>Path to configuration file. Defaults to a file named <code>config.yml</code> in the current working directory.</p> </li> <li> <p>--config-opt / -X ([]string)</p> <p>Option provided configuration (e.g. <code>-X timeoutMs=6000</code>). This is a repeatable option.</p> </li> </ul>"},{"location":"cmd/configure/","title":"configure","text":"<p>A short interactive prompt to guide through creating a configuration file.</p>"},{"location":"cmd/configure/#synopsis","title":"Synopsis","text":"<pre><code>kdef configure\n</code></pre>"},{"location":"cmd/global-options/","title":"Global options","text":"<ul> <li> <p>-no-color (bool)</p> <p>Disable colored output. The default value is <code>false</code>.</p> </li> <li> <p>--quiet / -q (boolean)</p> <p>Enable quiet mode (output errors only). The default value is <code>false</code>.</p> </li> <li> <p>--verbose / -v (boolean)</p> <p>Enable debug output. The default value is <code>false</code>.</p> </li> <li> <p>--config-path / -p (string)</p> <p>Path to configuration file. Defaults to a file named <code>config.yml</code> in the current working directory.</p> </li> <li> <p>--config-opt / -X ([]string)</p> <p>Option provided configuration (e.g. <code>-X timeoutMs=6000</code>). This is a repeatable option.</p> </li> </ul>"},{"location":"cmd/export/acl/","title":"acl","text":"<p>Export resource acls to definitions (Kafka 0.11.0+).</p>"},{"location":"cmd/export/acl/#synopsis","title":"Synopsis","text":"<pre><code>kdef export acl [options]\n</code></pre> <p>Exports to stdout by default. Supply the <code>--output-dir</code> option to create definition files.</p>"},{"location":"cmd/export/acl/#examples","title":"Examples","text":"<p>Export all resource acls to the directory \"acls\". <pre><code>kdef export acl --output-dir \"acls\"\n</code></pre></p> <p>Export all topic acls to stdout. <pre><code>kdef export acl --type topic --quiet\n</code></pre></p> <p>Export all resource acls starting with \"myapp\". <pre><code>kdef export acl --match \"myapp.*\"\n</code></pre></p>"},{"location":"cmd/export/acl/#options","title":"Options","text":"<ul> <li> <p>--format / -f (string)</p> <p>Resource definition format. Must be either <code>yaml</code> or <code>json</code>. The default value is <code>yaml</code>.</p> </li> <li> <p>--output-dir / -o (string)</p> <p>Output directory path for definition files. Non-existent directories will be created.</p> </li> <li> <p>--overwrite / -w (bool)</p> <p>Overwrite existing files in output directory. The default value is <code>false</code>.</p> </li> <li> <p>--match / -m (string)</p> <p>Regular expression matching resource names to include. The default value is <code>.*</code>.</p> </li> <li> <p>--exclude / -e (string)</p> <p>Regular expression matching resource names to exclude. The default value is <code>.^</code>.</p> </li> <li> <p>--type / -t (string)</p> <p>ACL resource type. Must be one of <code>any</code>, <code>topic</code>, <code>group</code>, <code>cluster</code>, <code>transactional_id</code>, <code>delegation_token</code>. The default value is <code>any</code>.</p> </li> <li> <p>--auto-group / -g (bool)</p> <p>Combine acls into groups for easier management. The default value is <code>true</code>.</p> <p>See ACLEntryGroup for further details.</p> </li> </ul>"},{"location":"cmd/export/acl/#global-options","title":"Global options","text":"<ul> <li> <p>-no-color (bool)</p> <p>Disable colored output. The default value is <code>false</code>.</p> </li> <li> <p>--quiet / -q (boolean)</p> <p>Enable quiet mode (output errors only). The default value is <code>false</code>.</p> </li> <li> <p>--verbose / -v (boolean)</p> <p>Enable debug output. The default value is <code>false</code>.</p> </li> <li> <p>--config-path / -p (string)</p> <p>Path to configuration file. Defaults to a file named <code>config.yml</code> in the current working directory.</p> </li> <li> <p>--config-opt / -X ([]string)</p> <p>Option provided configuration (e.g. <code>-X timeoutMs=6000</code>). This is a repeatable option.</p> </li> </ul>"},{"location":"cmd/export/broker/","title":"broker","text":"<p>Export per-broker configuration to definitions (Kafka 0.11.0+).</p>"},{"location":"cmd/export/broker/#synopsis","title":"Synopsis","text":"<pre><code>kdef export broker [options]\n</code></pre> <p>Exports to stdout by default. Supply the <code>--output-dir</code> option to create definition files.</p>"},{"location":"cmd/export/broker/#examples","title":"Examples","text":"<p>Export broker definitions to the directory \"broker\". <pre><code>kdef export broker --output-dir \"broker\"\n</code></pre></p> <p>Export broker definitions to stdout. <pre><code>kdef export broker --quiet\n</code></pre></p>"},{"location":"cmd/export/broker/#options","title":"Options","text":"<ul> <li> <p>--format / -f (string)</p> <p>Resource definition format. Must be either <code>yaml</code> or <code>json</code>. The default value is <code>yaml</code>.</p> </li> <li> <p>--output-dir / -o (string)</p> <p>Output directory path for definition files. Non-existent directories will be created.</p> </li> <li> <p>--overwrite / -w (bool)</p> <p>Overwrite existing files in output directory. The default value is <code>false</code>.</p> </li> </ul>"},{"location":"cmd/export/broker/#global-options","title":"Global options","text":"<ul> <li> <p>-no-color (bool)</p> <p>Disable colored output. The default value is <code>false</code>.</p> </li> <li> <p>--quiet / -q (boolean)</p> <p>Enable quiet mode (output errors only). The default value is <code>false</code>.</p> </li> <li> <p>--verbose / -v (boolean)</p> <p>Enable debug output. The default value is <code>false</code>.</p> </li> <li> <p>--config-path / -p (string)</p> <p>Path to configuration file. Defaults to a file named <code>config.yml</code> in the current working directory.</p> </li> <li> <p>--config-opt / -X ([]string)</p> <p>Option provided configuration (e.g. <code>-X timeoutMs=6000</code>). This is a repeatable option.</p> </li> </ul>"},{"location":"cmd/export/brokers/","title":"brokers","text":"<p>Export cluster-wide broker configuration to definitions (Kafka 0.11.0+).</p>"},{"location":"cmd/export/brokers/#synopsis","title":"Synopsis","text":"<pre><code>kdef export brokers [options]\n</code></pre> <p>Exports to stdout by default. Supply the <code>--output-dir</code> option to create definition files.</p>"},{"location":"cmd/export/brokers/#examples","title":"Examples","text":"<p>Export brokers definition to the directory \"brokers\". <pre><code>kdef export brokers --output-dir \"brokers\"\n</code></pre></p> <p>Export brokers definition to stdout. <pre><code>kdef export brokers --quiet\n</code></pre></p>"},{"location":"cmd/export/brokers/#options","title":"Options","text":"<ul> <li> <p>--format / -f (string)</p> <p>Resource definition format. Must be either <code>yaml</code> or <code>json</code>. The default value is <code>yaml</code>.</p> </li> <li> <p>--output-dir / -o (string)</p> <p>Output directory path for definition files. Non-existent directories will be created.</p> </li> <li> <p>--overwrite / -w (bool)</p> <p>Overwrite existing files in output directory. The default value is <code>false</code>.</p> </li> </ul>"},{"location":"cmd/export/brokers/#global-options","title":"Global options","text":"<ul> <li> <p>-no-color (bool)</p> <p>Disable colored output. The default value is <code>false</code>.</p> </li> <li> <p>--quiet / -q (boolean)</p> <p>Enable quiet mode (output errors only). The default value is <code>false</code>.</p> </li> <li> <p>--verbose / -v (boolean)</p> <p>Enable debug output. The default value is <code>false</code>.</p> </li> <li> <p>--config-path / -p (string)</p> <p>Path to configuration file. Defaults to a file named <code>config.yml</code> in the current working directory.</p> </li> <li> <p>--config-opt / -X ([]string)</p> <p>Option provided configuration (e.g. <code>-X timeoutMs=6000</code>). This is a repeatable option.</p> </li> </ul>"},{"location":"cmd/export/topic/","title":"topic","text":"<p>Export topics to definitions (Kafka 0.11.0+).</p>"},{"location":"cmd/export/topic/#synopsis","title":"Synopsis","text":"<pre><code>kdef export topic [options]\n</code></pre> <p>Exports to stdout by default. Supply the <code>--output-dir</code> option to create definition files.</p>"},{"location":"cmd/export/topic/#examples","title":"Examples","text":"<p>Export all topics to the directory \"topics\". <pre><code>kdef export topic --output-dir \"topics\"\n</code></pre></p> <p>Export all topics to stdout. <pre><code>kdef export topic --quiet\n</code></pre></p> <p>Export all topics starting with \"myapp\" <pre><code>kdef export topic --match \"myapp.*\"\n</code></pre></p>"},{"location":"cmd/export/topic/#options","title":"Options","text":"<ul> <li> <p>--format / -f (string)</p> <p>Resource definition format. Must be either <code>yaml</code> or <code>json</code>. The default value is <code>yaml</code>.</p> </li> <li> <p>--output-dir / -o (string)</p> <p>Output directory path for definition files. Non-existent directories will be created.</p> </li> <li> <p>--overwrite / -w (bool)</p> <p>Overwrite existing files in output directory. The default value is <code>false</code>.</p> </li> <li> <p>--match / -m (string)</p> <p>Regular expression matching topic names to include. The default value is <code>.*</code>.</p> </li> <li> <p>--exclude / -e (string)</p> <p>Regular expression matching topic names to exclude. The default value is <code>.^</code>.</p> </li> <li> <p>--include-internal / -i (bool)</p> <p>Include internal topics. The default value is <code>false</code>.</p> </li> <li> <p>--assignments / -a (string)</p> <p>Partition assignments to include in topic definitions. Must be one of <code>none</code>, <code>broker</code>, <code>rack</code>. The default value is <code>none</code>.</p> </li> </ul>"},{"location":"cmd/export/topic/#global-options","title":"Global options","text":"<ul> <li> <p>-no-color (bool)</p> <p>Disable colored output. The default value is <code>false</code>.</p> </li> <li> <p>--quiet / -q (boolean)</p> <p>Enable quiet mode (output errors only). The default value is <code>false</code>.</p> </li> <li> <p>--verbose / -v (boolean)</p> <p>Enable debug output. The default value is <code>false</code>.</p> </li> <li> <p>--config-path / -p (string)</p> <p>Path to configuration file. Defaults to a file named <code>config.yml</code> in the current working directory.</p> </li> <li> <p>--config-opt / -X ([]string)</p> <p>Option provided configuration (e.g. <code>-X timeoutMs=6000</code>). This is a repeatable option.</p> </li> </ul>"},{"location":"def/acl/","title":"acl","text":"<p>A definition representing ACLs for a specified Kafka resource.</p>"},{"location":"def/acl/#definition","title":"Definition","text":"<ul> <li>apiVersion: v1</li> <li>kind: acl</li> <li>metadata (Metadata)</li> <li>spec (Spec)</li> </ul>"},{"location":"def/acl/#metadata","title":"Metadata","text":"<ul> <li> <p>name (string), required</p> <p>The name of the resource that ACL entries will be applied to. For type <code>cluster</code> this must be <code>kafka-cluster</code>.</p> </li> <li> <p>type (string), required</p> <p>The type of the resource that ACL entries will be applied to. Must be one of <code>topic</code>, <code>group</code>, <code>cluster</code>, <code>transactional_id</code>, <code>delegation_token</code>.</p> </li> <li> <p>resourcePatternType (string)</p> <p>How the resource name will be understood by Kafka. Must be one of <code>literal</code>, <code>prefixed</code>. The default value is <code>literal</code>.</p> </li> <li> <p>labels (map[string]string)</p> <p>Labels are key-value pairs associated with the definition.</p> <p>Labels are not directly used by kdef and have no remote state. They are purely for the purposes of storing meaningful attributes with the definition that would be relevant to users.</p> </li> </ul>"},{"location":"def/acl/#spec","title":"Spec","text":"<ul> <li>acls ([]ACLEntryGroup)</li> <li> <p>deleteUndefinedAcls (bool)</p> <p>Allows kdef to delete ACLs that are not defined in <code>acls</code>. It is highly recommended to set this to <code>true</code>. If <code>false</code>, changes to ACL entry groups will only create new ACLs and previously defined ACLs will remain attached to the target resource.</p> <p>Caution</p> <p>Enabling allows kdef to permanently delete ACLs. Always confirm operations with <code>--dry-run</code>.</p> </li> </ul>"},{"location":"def/acl/#aclentrygroup","title":"ACLEntryGroup","text":"<p>A group of ACL entries, where specifying more than one value for its properties results in many ACLs being created in a combinatorial fashion.</p> <p>Example</p> <p>The following ACL entry group creates six ACLs. <pre><code>    - hosts: [\"*\"]\n    operations: [\"READ\", \"WRITE\"]\n    permissionType: ALLOW\n    principals:\n        - User:foo\n        - User:bar\n        - User:baz\n</code></pre> <pre><code>\"*\", \"READ\", \"ALLOW\", \"User:foo\"\n\"*\", \"READ\", \"ALLOW\", \"User:bar\"\n\"*\", \"READ\", \"ALLOW\", \"User:baz\"\n\"*\", \"WRITE\", \"ALLOW\", \"User:foo\"\n\"*\", \"WRITE\", \"ALLOW\", \"User:bar\"\n\"*\", \"WRITE\", \"ALLOW\", \"User:baz\"\n</code></pre></p> <ul> <li> <p>hosts ([]string), required</p> <p>Host addresses to create ACLs for. The wildcard \"*\" allows all hosts.</p> </li> <li> <p>operations ([]string), required</p> <p>Operations to create ACLs for. Must be one of <code>ALL</code>, <code>READ</code>, <code>WRITE</code>, <code>CREATE</code>, <code>DELETE</code>, <code>ALTER</code>, <code>DESCRIBE</code>, <code>CLUSTER_ACTION</code>, <code>DESCRIBE_CONFIGS</code>,<code>ALTER_CONFIGS</code>,<code>IDEMPOTENT_WRITE</code>.</p> </li> <li> <p>permissionType (string), required</p> <p>The permission type for ACLs in this group. Must be either <code>ALLOW</code> or <code>DENY</code>.</p> </li> <li> <p>principals ([]string), required</p> <p>Principals to create ACLs for. When using Kafka simple authorizer, this must begin with <code>User:</code>.</p> </li> </ul>"},{"location":"def/acl/#examples","title":"Examples","text":"<pre><code>apiVersion: v1\nkind: acl\nmetadata:\n  name: kafka-cluster\n  type: cluster\nspec:\n  acls:\n    - hosts: [\"*\"]\n      operations: [\"DESCRIBE_CONFIGS\"]\n      permissionType: ALLOW\n      principals:\n        - User:foo\n        - User:bar\n        - User:baz\n  deleteUndefinedAcls: true\n</code></pre> <pre><code>apiVersion: v1\nkind: acl\nmetadata:\n  name: store.events.order-created\n  type: topic\n  labels:\n    producer: storefront\nspec:\n  acls:\n    - hosts: [\"*\"]\n      operations:\n        - \"READ\"\n        - \"WRITE\"\n        - \"CREATE\"\n        - \"DESCRIBE\"\n        - \"DESCRIBE_CONFIGS\"\n      permissionType: ALLOW\n      principals:\n        - User:foo\n        - User:bar\n        - User:baz\n    - hosts: [\"*\"]\n      operations:\n        - \"DELETE\"\n        - \"ALTER\"\n        - \"ALTER_CONFIGS\"\n      permissionType: ALLOW\n      principals: [\"User:baz\"]\n    - hosts: [\"*\"]\n      operations: [\"CREATE\"]\n      permissionType: DENY\n      principals: [\"User:bar\"]\n  deleteUndefinedAcls: true\n</code></pre>"},{"location":"def/acl/#schema","title":"Schema","text":"<p>Definition: <pre><code>{\n    \"apiVersion\": string,\n    \"kind\": string,\n    \"metadata\": {\n        \"name\": string,\n        \"type\": string,\n        \"labels\": [\n            string\n        ]\n    },\n    \"spec\": {\n        \"acls\": [\n            {\n                \"hosts\": [\n                    string\n                ],\n                \"operations\": [\n                    string\n                ],\n                \"permissionType\": string,\n                \"principals\": [\n                    string\n                ]\n            }\n        ],\n        \"deleteUndefinedAcls\": bool\n    }\n}\n</code></pre></p>"},{"location":"def/broker/","title":"broker","text":"<p>A definition representing a single specified Kafka broker.</p>"},{"location":"def/broker/#definition","title":"Definition","text":"<ul> <li>apiVersion: v1</li> <li>kind: broker</li> <li>metadata (Metadata)</li> <li>spec (Spec)</li> </ul>"},{"location":"def/broker/#metadata","title":"Metadata","text":"<ul> <li> <p>name (string), required</p> <p>The ID of the target broker.</p> </li> <li> <p>labels (map[string]string)</p> <p>Labels are key-value pairs associated with the definition.</p> <p>Labels are not directly used by kdef and have no remote state. They are purely for the purposes of storing meaningful attributes with the definition that would be relevant to users.</p> </li> </ul>"},{"location":"def/broker/#spec","title":"Spec","text":"<ul> <li> <p>configs (map[string]string)</p> <p>A map of key-value config pairs.</p> <p>Note that Kafka's API does not allow reading <code>password</code> type broker configs. Applying these configs is supported, but <code>kdef apply</code> will always show a diff for them.</p> </li> <li> <p>deleteUndefinedConfigs (bool)</p> <p>Allows kdef to delete configs that are not defined in <code>configs</code>.</p> <p>Caution</p> <p>Enabling allows kdef to permanently delete configs. Always confirm operations with <code>--dry-run</code>.</p> </li> </ul>"},{"location":"def/broker/#examples","title":"Examples","text":"<pre><code>apiVersion: v1\nkind: broker\nmetadata:\n  name: \"1\"\nspec:\n  configs:\n    leader.replication.throttled.rate: \"700000000\"\n    follower.replication.throttled.rate: \"700000000\"\n</code></pre>"},{"location":"def/broker/#schema","title":"Schema","text":"<p>Definition: <pre><code>{\n    \"apiVersion\": string,\n    \"kind\": string,\n    \"metadata\": {\n        \"name\": string,\n        \"labels\": [\n            string\n        ]\n    },\n    \"spec\": {\n        \"configs\": {\n            string: string\n        },\n        \"deleteUndefinedConfigs\": bool\n    }\n}\n</code></pre></p>"},{"location":"def/brokers/","title":"brokers","text":"<p>A definition representing cluster-wide configuration for all Kafka brokers.</p>"},{"location":"def/brokers/#definition","title":"Definition","text":"<ul> <li>apiVersion: v1</li> <li>kind: brokers</li> <li>metadata (Metadata)</li> <li>spec (Spec)</li> </ul>"},{"location":"def/brokers/#metadata","title":"Metadata","text":"<ul> <li> <p>name (string), required</p> <p>An identifier for the definition.</p> <p>This is not used directly by kdef and can be any meaningful value for reference.</p> </li> <li> <p>labels (map[string]string)</p> <p>Labels are key-value pairs associated with the definition.</p> <p>Labels are not directly used by kdef and have no remote state. They are purely for the purposes of storing meaningful attributes with the definition that would be relevant to users.</p> </li> </ul>"},{"location":"def/brokers/#spec","title":"Spec","text":"<ul> <li> <p>configs (map[string]string)</p> <p>A map of key-value config pairs.</p> </li> <li> <p>deleteUndefinedConfigs (bool)</p> <p>Allows kdef to delete configs that are not defined in <code>configs</code>.</p> <p>Caution</p> <p>Enabling allows kdef to permanently delete configs. Always confirm operations with <code>--dry-run</code>.</p> </li> </ul>"},{"location":"def/brokers/#examples","title":"Examples","text":"<pre><code>apiVersion: v1\nkind: brokers\nmetadata:\n  name: store-cluster\nspec:\n  configs:\n    leader.replication.throttled.rate: \"700000000\"\n    follower.replication.throttled.rate: \"700000000\"\n</code></pre>"},{"location":"def/brokers/#schema","title":"Schema","text":"<p>Definition: <pre><code>{\n    \"apiVersion\": string,\n    \"kind\": string,\n    \"metadata\": {\n        \"name\": string,\n        \"labels\": [\n            string\n        ]\n    },\n    \"spec\": {\n        \"configs\": {\n            string: string\n        },\n        \"deleteUndefinedConfigs\": bool\n    }\n}\n</code></pre></p>"},{"location":"def/topic/","title":"topic","text":"<p>A definition representing a Kafka topic.</p>"},{"location":"def/topic/#definition","title":"Definition","text":"<ul> <li>apiVersion: v1</li> <li>kind: topic</li> <li>metadata (Metadata)</li> <li>spec (Spec)</li> <li> <p>state (State)</p> <p>An internal-use only property group that kdef uses to show underlying state changes.</p> </li> </ul>"},{"location":"def/topic/#metadata","title":"Metadata","text":"<ul> <li> <p>name (string), required</p> <p>The topic name.</p> </li> <li> <p>labels (map[string]string)</p> <p>Labels are key-value pairs associated with the definition.</p> <p>Labels are not directly used by kdef and have no remote state. They are purely for the purposes of storing meaningful attributes with the definition that would be relevant to users.</p> </li> </ul>"},{"location":"def/topic/#spec","title":"Spec","text":"<ul> <li> <p>configs (map[string]string)</p> <p>A map of key-value config pairs.</p> </li> <li> <p>deleteUndefinedConfigs (bool)</p> <p>Allows kdef to delete configs that are not defined in <code>configs</code>.</p> <p>Caution</p> <p>Enabling allows kdef to permanently delete configs. Always confirm operations with <code>--dry-run</code>.</p> </li> <li> <p>partitions (int), required</p> <p>Number of partitions for the topic.</p> <p>Note that decreasing the number of partitions is not supported.</p> </li> <li> <p>replicationFactor (int), required</p> <p>Replication factor for the topic. Cannot exceed the number of available brokers.</p> </li> <li> <p>assignments ([][]int)</p> <p>Partition replica assignments by broker ID. The number of replica assignments must match <code>partitions</code>, and the number of replicas in each assignment must match <code>replicationFactor</code>. A replica assignment for a partition cannot contain duplicate broker IDs.</p> <p>Cannot be specified at the same time as <code>managedAssignments</code>.</p> <p>Example</p> <p>Assignments for 3 partitions with a replication factor of 2. <pre><code>assignments:\n- [1, 2]\n- [2, 3]\n- [3, 1]\n</code></pre></p> </li> <li> <p>managedAssignments (ManagedAssignments)</p> <p>Configuration for kdef-managed partition assignments. The definition will default to managed assignments if <code>assignments</code> are not specified.</p> <p>Cannot be specified at the same time as <code>assignments</code>.</p> </li> <li> <p>maintainLeaders (bool)</p> <p>Performs leader election on the preferred leader (the first replica in the assignment) of partitions if leadership has been lost to another broker.</p> <p>The default value is <code>false</code>.</p> </li> </ul>"},{"location":"def/topic/#managedassignments","title":"ManagedAssignments","text":"<p>When using managed assignments, kdef will make evenly distributed replica assignments based on the configuration in this section.</p> <p>kdef employs a general strategy of balancing partition replicas across available brokers for topic performance and availability. In particular, partition leaders (the first replica in the assignment) are evenly distributed across available brokers.</p> <ul> <li> <p>rackConstraints ([][]string)</p> <p>Rack ID constraints for partition replica assignment. kdef will maintain evenly distributed replica assignments constrained by the specified racks. The number of rack constraints must match <code>partitions</code>, and the number of replicas in a partition's rack constraints must match <code>replicationFactor</code>.</p> <p>Example</p> <p>Rack constraints for 3 partitions with a replication factor of 2. <pre><code>rackConstraints:\n  - [\"zone-a\", \"zone-b\"]\n  - [\"zone-b\", \"zone-c\"]\n  - [\"zone-c\", \"zone-a\"]\n</code></pre></p> <p>Rack constraints for 3 partitions with a replication factor of 3. This example ensures each partition's leader and follower replicas are all in the same rack. <pre><code>rackConstraints:\n  - [\"zone-a\", \"zone-a\", \"zone-a\"]\n  - [\"zone-b\", \"zone-b\", \"zone-b\"]\n  - [\"zone-c\", \"zone-c\", \"zone-c\"]\n</code></pre></p> </li> <li> <p>selection (string)</p> <p>The method used to select a broker for a replica. After constraints have been applied, each replica assignment is selected from a pool of qualifying brokers using this method.</p> <p>Selection methods:</p> <ul> <li><code>topic-cluster-use</code> (default) - Maintain balanced usage of brokers within the topic and cluster. Broker selection for a replica is made based on broker usage within the topic, breaking ties with broker usage across the cluster.</li> <li><code>topic-use</code> - Maintain balanced usage of brokers within the topic. Broker selection for a replica is made based on broker usage within the topic.</li> </ul> <p>If the above selection methods are unable to narrow the pool to a single broker, ties will broken in two ways. When adding replicas, ties will be broken with round-robin broker ID. When removing replicas, ties will be broken with the highest replica index.</p> </li> <li> <p>balance (string)</p> <p>The scope of the managed assignments strategy when a topic is applied.</p> <p>Balance scopes:</p> <ul> <li><code>new</code> (default) - Only new assignments are balanced by the managed strategy. New assignments refers to additional replicas added when partitions are increased, or the replication factor is increased.</li> <li><code>all</code> - All assignments are in scope of the managed strategy, and changes may be made to rebalance replicas across available brokers. Setting this scope is equivalent to performing a partition rebalance on apply.</li> </ul> <p>Tip</p> <p>Setting scope <code>all</code> permanently in definitions could be disruputive if activity in the cluster causes frequent rebalancing. Consider only periodically rebalancing by using the apply command's property override <code>-P</code> option to chose when to set the <code>all</code> scope.</p> <p>i.e. <code>-P topic.spec.managedAssignments.balance=all</code></p> </li> </ul>"},{"location":"def/topic/#examples","title":"Examples","text":"<pre><code>apiVersion: v1\nkind: topic\nmetadata:\n  name: store.events.order-created\n  labels:\n    producer: storefront\nspec:\n  configs:\n    retention.ms: \"86400000\"\n  partitions: 3\n  replicationFactor: 2\n</code></pre> <pre><code>apiVersion: v1\nkind: topic\nmetadata:\n  name: store.events.order-updated\n  labels:\n    producer: storefront\nspec:\n  configs:\n    retention.ms: \"86400000\"\n  partitions: 6\n  replicationFactor: 2\n  assignments:\n    - [1, 2]\n    - [2, 3]\n    - [3, 1]\n    - [1, 2]\n    - [2, 3]\n    - [3, 1]\n</code></pre> <pre><code>apiVersion: v1\nkind: topic\nmetadata:\n  name: store.events.order-picked\n  labels:\n    producer: backoffice\nspec:\n  configs:\n    retention.ms: \"86400000\"\n  partitions: 4\n  replicationFactor: 2\n  managedAssignments:\n    rackConstraints:\n      - [\"zone-a\", \"zone-b\"]\n      - [\"zone-b\", \"zone-c\"]\n      - [\"zone-c\", \"zone-a\"]\n      - [\"zone-a\", \"zone-b\"]\n</code></pre> <pre><code>apiVersion: v1\nkind: topic\nmetadata:\n  name: store.events.order-dispatched\n  labels:\n    producer: backoffice\nspec:\n  configs:\n    cleanup.policy: delete\n    compression.type: producer\n    delete.retention.ms: \"86400000\"\n    file.delete.delay.ms: \"60000\"\n    flush.messages: \"9223372036854775807\"\n    flush.ms: \"9223372036854775807\"\n    follower.replication.throttled.replicas: \"\"\n    index.interval.bytes: \"4096\"\n    leader.replication.throttled.replicas: \"\"\n    max.compaction.lag.ms: \"9223372036854775807\"\n    max.message.bytes: \"1048588\"\n    message.downconversion.enable: \"true\"\n    message.format.version: 2.8-IV1\n    message.timestamp.difference.max.ms: \"9223372036854775807\"\n    message.timestamp.type: CreateTime\n    min.cleanable.dirty.ratio: \"0.5\"\n    min.compaction.lag.ms: \"0\"\n    min.insync.replicas: \"2\"\n    preallocate: \"false\"\n    retention.bytes: \"-1\"\n    retention.ms: \"604800000\"\n    segment.bytes: \"1073741824\"\n    segment.index.bytes: \"10485760\"\n    segment.jitter.ms: \"0\"\n    segment.ms: \"604800000\"\n    unclean.leader.election.enable: \"false\"\n  deleteUndefinedConfigs: true\n  partitions: 3\n  replicationFactor: 2\n</code></pre>"},{"location":"def/topic/#schema","title":"Schema","text":"<p>Definition: <pre><code>{\n    \"apiVersion\": string,\n    \"kind\": string,\n    \"metadata\": {\n        \"name\": string,\n        \"labels\": [\n            string\n        ]\n    },\n    \"spec\": {\n        \"configs\": {\n            string: string\n        },\n        \"deleteUndefinedConfigs\": bool,\n        \"partitions\": int,\n        \"replicationFactor\": int,\n        \"assignments\": [\n            [\n                int\n            ]\n        ],\n        \"managedAssignments\": {\n            \"rackConstraints\": [\n                [\n                    string\n                ]\n            ],\n            \"selection\": string,\n            \"balance\": string\n        },\n        \"maintainLeaders\": bool\n    },\n    \"state\": {\n        \"assignments\": [\n            [\n                int\n            ]\n        ],\n        \"leaders\": [\n            int\n        ]\n    }\n}\n</code></pre></p> <p>Additional Data:</p> <p>The following additional data is output with the apply result when using the <code>--json-output</code> option. <pre><code>{\n    \"partitionReassignments\": null|[\n        {\n            \"partition\": int,\n            \"replicas\": [\n                int\n            ],\n            \"addingReplicas\": null|[\n                int\n            ],\n            \"removingReplicas\": null|[\n                int\n            ]\n        }\n    ]\n}\n</code></pre></p>"}]}